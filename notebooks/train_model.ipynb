{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/thomas/ai/Heuristik/data/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/thomas/ai/Heuristik/data/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "import argparse\n",
    "import wandb\n",
    "import os\n",
    "import heuristik\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            Using <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> in dryrun mode. Not logging results to the cloud.<br/>\n",
       "            Call wandb.login() to authenticate this machine.<br/>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(barriers='5%', batch_size=32, bert_model_name='bert-base-cased', binary_sentiment=True, data_version='4_long', dryrun=True, epochs=10, max_len=100, nonbinary_sentiment=False, num_classes=2, path='/home/thomas/ai/Heuristik/data/', pretrained_model='BaseModel_large', print_freq=50, seed=4, session='Huggingface_dev', timeframe='3 days')\n",
      "Loading pre-trained model: /home/thomas/ai/Heuristik/data/BaseModel_large.pth\n",
      "Successfully retrieved 45.1k samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Arg Parser\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Heuristik: Asset News Recommendations')\n",
    "parser.add_argument('--data_version', default='3_large', type=str, help='data version Default: 3_large')\n",
    "parser.add_argument('--path', default='/home/thomas/ai/asset_sentiments/Examples/heuristik_data/', type=str, help='Path to data folder.')\n",
    "parser.add_argument('--timeframe', default='3 days', type=str, help='Price data time window. Default: ')\n",
    "parser.add_argument('--barriers', default='5%', type=str, help='Vertical price window barriers in percent. Default: 3 days')\n",
    "parser.add_argument('--nonbinary_sentiment', action='store_true', help='Enable positive/negative predictions for price. Default: 5%')\n",
    "parser.add_argument('--seed', type=int, default = 4, help='Enable positive/negative predictions for price. Default: 3')\n",
    "parser.add_argument('--bert_model_name', default = 'bert-base-cased', help='Give Huggingface BERT model name. Default: bert-base-cased')\n",
    "parser.add_argument('--max_len', type=int, default = 50, help='Maximum number of words to keep in sample. Default: 50')\n",
    "parser.add_argument('--batch_size', type=int, default = 32, help='Batch size. Default: 32')\n",
    "parser.add_argument('--epochs', type=int, default = 10, help='Number of epochs. Default: 10')\n",
    "parser.add_argument('--pretrained_model', default='None', type=str, help='Name of pretrained model. Options: base, AAPL, MSFT,... Default: None')\n",
    "parser.add_argument('--print_freq', type=int, default = 50, help='Print frequency during training. Default: 50')\n",
    "parser.add_argument('--session', default='Huggingface_dev', type=str, help='Session name for W&B.')\n",
    "parser.add_argument('--dryrun', action='store_true', help='Disable W&B logging.')\n",
    "\n",
    "args = parser.parse_args(['--data_version',  '4_long',\n",
    "                          '--path', '/home/thomas/ai/Heuristik/data',\n",
    "                          '--timeframe','3 days',\n",
    "                          '--barriers', '5%',\n",
    "                          '--epochs','10',\n",
    "                          '--max_len','100',\n",
    "                          '--dryrun',\n",
    "                          '--batch_size','32',\n",
    "                          '--pretrained_model','BaseModel_large'\n",
    "                         ])\n",
    "\n",
    "if args.dryrun:\n",
    "    os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "wandb.init(project = 'Heuristik',  entity='tbachlechner', name = args.session+'_'+str(args.seed))\n",
    "\n",
    "args.binary_sentiment = not args.nonbinary_sentiment\n",
    "\n",
    "args.num_classes = 2\n",
    "if not args.binary_sentiment:\n",
    "    args.num_classes = 3\n",
    "if args.path[-1] != '/':\n",
    "    args.path = args.path+'/'\n",
    "print(args)\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = heuristik.load_model(model_name =args.bert_model_name, n_classes = args.num_classes, pretrained = args.pretrained_model,path = args.path)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Load data into dataframe\n",
    "\n",
    "data = heuristik.data(path = args.path,\n",
    "                    timeframe = args.timeframe, \n",
    "                    data_version = args.data_version, \n",
    "                    barriers =  args.barriers,\n",
    "                    binary_sentiment = args.binary_sentiment)\n",
    "\n",
    "df = data.retrieve(symbols = ['TWTR','AMD','BP','TWTR','PTON','PYPL','ZM','ACN','FB','AAPL','AMZN','MSFT','TSLA','GOOG','NFLX','BAC','XOM','BA','IGT'],download=True)\n",
    "\n",
    "# Load data into loaders\n",
    "\n",
    "loaders = heuristik.prepare_loaders(df,\n",
    "                          bert_model_name = args.bert_model_name, \n",
    "                          max_len = args.max_len, \n",
    "                          batch_size = args.batch_size,\n",
    "                          seed = args.seed,\n",
    "                        test_size = 0.1)\n",
    "\n",
    "dl_train, dl_val, dl_test = loaders.train_val_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct ratio: 0.78\n",
      "Epoch:  0 Val. Loss: 0.069.  Acc: 88. F1:  0.422\n",
      "Epoch 1/10\n",
      "----------\n",
      "Batch:  50/1270. Train Loss: 0.017  Acc: 90 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-dd1331a4b7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m heuristik.train_model(epochs = args.epochs, \n\u001b[0m\u001b[1;32m      2\u001b[0m                       \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                       \u001b[0mdl_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                       \u001b[0mdl_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai/Heuristik/src/training.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, model, dl_train, device, dl_val, path, file_name, print_freq)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m         train_acc, train_loss = train_epoch(\n\u001b[0m\u001b[1;32m    353\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ai/Heuristik/src/training.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(epoch, model, data_loader, loss_fn, optimizer, device, scheduler, print_freq)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/heuristik/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/heuristik/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "heuristik.train_model(epochs = args.epochs, \n",
    "                      model = model, \n",
    "                      dl_train = dl_train,\n",
    "                      dl_val = dl_val, \n",
    "                      path = args.path, \n",
    "                      file_name = 'BaseModel_large.pth',\n",
    "                      device = device,\n",
    "                      print_freq=args.print_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
