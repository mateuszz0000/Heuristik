{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/thomas/ai/Heuristik/data/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/thomas/ai/Heuristik/data/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "import argparse\n",
    "import wandb\n",
    "import os\n",
    "os.environ[\"heuristik_data_path\"] = '~/ai/Heuristik/data'\n",
    "import heuristik\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://app.wandb.ai/tbachlechner/Heuristik\" target=\"_blank\">https://app.wandb.ai/tbachlechner/Heuristik</a><br/>\n",
       "                Run page: <a href=\"https://app.wandb.ai/tbachlechner/Heuristik/runs/oxnrt45u\" target=\"_blank\">https://app.wandb.ai/tbachlechner/Heuristik/runs/oxnrt45u</a><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(barriers='5%', batch_size=32, bert_model_name='bert-base-cased', binary_sentiment=True, data_version='4_long', dryrun=False, epochs=10, max_len=100, nonbinary_sentiment=False, num_classes=2, path='/home/thomas/ai/Heuristik/data', pretrained_model='BaseModel_rezero', print_freq=50, seed=6, session='rezero_dev', timeframe='3 days')\n",
      "Successfully retrieved 43.9k samples.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Arg Parser\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Heuristik: Asset News Recommendations')\n",
    "parser.add_argument('--data_version', default='3_large', type=str, help='data version Default: 3_large')\n",
    "parser.add_argument('--path', default='/home/thomas/ai/asset_sentiments/Examples/heuristik_data/', type=str, help='Path to data folder.')\n",
    "parser.add_argument('--timeframe', default='3 days', type=str, help='Price data time window. Default: ')\n",
    "parser.add_argument('--barriers', default='5%', type=str, help='Vertical price window barriers in percent. Default: 3 days')\n",
    "parser.add_argument('--nonbinary_sentiment', action='store_true', help='Enable positive/negative predictions for price. Default: 5%')\n",
    "parser.add_argument('--seed', type=int, default = 6, help='Enable positive/negative predictions for price. Default: 3')\n",
    "parser.add_argument('--bert_model_name', default = 'bert-base-cased', help='Give Huggingface BERT model name. Default: bert-base-cased')\n",
    "parser.add_argument('--max_len', type=int, default = 50, help='Maximum number of words to keep in sample. Default: 50')\n",
    "parser.add_argument('--batch_size', type=int, default = 32, help='Batch size. Default: 32')\n",
    "parser.add_argument('--epochs', type=int, default = 10, help='Number of epochs. Default: 10')\n",
    "parser.add_argument('--pretrained_model', default='None', type=str, help='Name of pretrained model. Options: base, AAPL, MSFT,... Default: None')\n",
    "parser.add_argument('--print_freq', type=int, default = 50, help='Print frequency during training. Default: 50')\n",
    "parser.add_argument('--session', default='rezero_dev', type=str, help='Session name for W&B.')\n",
    "parser.add_argument('--dryrun', action='store_true', help='Disable W&B logging.')\n",
    "\n",
    "args = parser.parse_args(['--data_version',  '4_long',\n",
    "                          '--path', '/home/thomas/ai/Heuristik/data',\n",
    "                          '--timeframe','3 days',\n",
    "                          '--barriers', '5%',\n",
    "                          '--epochs','10',\n",
    "                          '--max_len','100',\n",
    "                          #'--dryrun',\n",
    "                          '--batch_size','32',\n",
    "                          '--pretrained_model','BaseModel_rezero'\n",
    "                         ])\n",
    "\n",
    "if args.dryrun:\n",
    "    os.environ['WANDB_MODE'] = 'dryrun'\n",
    "\n",
    "wandb.init(project = 'Heuristik',  entity='tbachlechner', name = args.session+'_'+str(args.seed))\n",
    "\n",
    "args.binary_sentiment = not args.nonbinary_sentiment\n",
    "\n",
    "args.num_classes = 2\n",
    "if not args.binary_sentiment:\n",
    "    args.num_classes = 3\n",
    "\n",
    "print(args)\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = heuristik.load_model(model_name =args.bert_model_name, n_classes = args.num_classes, pretrained = 'None',path = args.path,rezero = True)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# Load data into dataframe\n",
    "\n",
    "data = heuristik.data(\n",
    "                    timeframe = args.timeframe, \n",
    "                    data_version = args.data_version, \n",
    "                    barriers =  args.barriers,\n",
    "                    binary_sentiment = args.binary_sentiment)\n",
    "\n",
    "df = data.retrieve(symbols = ['TWTR','AMD','BP','PTON','PYPL','ZM','ACN','FB','AAPL','AMZN','MSFT','TSLA','GOOG','NFLX','BAC','XOM','BA','IGT'],download=True)\n",
    "\n",
    "\n",
    "# Load data into loaders\n",
    "loaders = heuristik.prepare_loaders(df,\n",
    "                          bert_model_name = args.bert_model_name, \n",
    "                          max_len = args.max_len, \n",
    "                          batch_size = args.batch_size,\n",
    "                          seed = args.seed,\n",
    "                          test_size = 0.1)\n",
    "\n",
    "dl_train, dl_val, dl_test = loaders.train_val_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct ratio: 0.16\n",
      "Epoch:  0 Val. Loss: 0.032.  Acc: 86. F1:  0.049\n",
      "Epoch 1/10\n",
      "----------\n",
      "Batch:  50/1235. Train Loss: 0.038  Acc: 79 \n",
      "Batch: 100/1235. Train Loss: 0.036  Acc: 81 \n",
      "Batch: 150/1235. Train Loss: 0.033  Acc: 83 \n",
      "Batch: 200/1235. Train Loss: 0.032  Acc: 84 \n",
      "Batch: 250/1235. Train Loss: 0.030  Acc: 85 \n",
      "Batch: 300/1235. Train Loss: 0.029  Acc: 86 \n",
      "Batch: 350/1235. Train Loss: 0.029  Acc: 86 \n",
      "Batch: 400/1235. Train Loss: 0.029  Acc: 86 \n",
      "Batch: 450/1235. Train Loss: 0.028  Acc: 86 \n",
      "Batch: 500/1235. Train Loss: 0.028  Acc: 86 \n",
      "Batch: 550/1235. Train Loss: 0.028  Acc: 86 \n",
      "Batch: 600/1235. Train Loss: 0.028  Acc: 86 \n",
      "Batch: 650/1235. Train Loss: 0.027  Acc: 86 \n",
      "Batch: 700/1235. Train Loss: 0.027  Acc: 86 \n",
      "Batch: 750/1235. Train Loss: 0.027  Acc: 86 \n",
      "Batch: 800/1235. Train Loss: 0.027  Acc: 87 \n",
      "Batch: 850/1235. Train Loss: 0.027  Acc: 87 \n",
      "Batch: 900/1235. Train Loss: 0.027  Acc: 87 \n",
      "Batch: 950/1235. Train Loss: 0.027  Acc: 87 \n",
      "Batch: 1000/1235. Train Loss: 0.026  Acc: 87 \n",
      "Batch: 1050/1235. Train Loss: 0.026  Acc: 87 \n",
      "Batch: 1100/1235. Train Loss: 0.027  Acc: 87 \n",
      "Batch: 1150/1235. Train Loss: 0.026  Acc: 87 \n",
      "Batch: 1200/1235. Train Loss: 0.026  Acc: 87 \n",
      "Time/epoch: 612\n",
      "-----------\n",
      "Epoch:  0 Val. Loss: 0.024.  Acc: 87. F1:  0.000\n",
      "Correct ratio: 0.52\n",
      "Save. Epoch:  1\n",
      "Epoch 2/10\n",
      "----------\n",
      "Batch:  50/1235. Train Loss: 0.024  Acc: 87 \n",
      "Batch: 100/1235. Train Loss: 0.025  Acc: 86 \n",
      "Batch: 150/1235. Train Loss: 0.025  Acc: 87 \n",
      "Batch: 200/1235. Train Loss: 0.024  Acc: 87 \n",
      "Batch: 250/1235. Train Loss: 0.024  Acc: 87 \n",
      "Batch: 300/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 350/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 400/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 450/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 500/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 550/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 600/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 650/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 700/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 750/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 800/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 850/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 900/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 950/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 1000/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 1050/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 1100/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 1150/1235. Train Loss: 0.023  Acc: 87 \n",
      "Batch: 1200/1235. Train Loss: 0.023  Acc: 87 \n",
      "Time/epoch: 617\n",
      "-----------\n",
      "Epoch:  1 Val. Loss: 0.023.  Acc: 87. F1:  0.021\n",
      "Correct ratio: 0.54\n",
      "Save. Epoch:  2\n",
      "Epoch 3/10\n",
      "----------\n",
      "Batch:  50/1235. Train Loss: 0.022  Acc: 87 \n",
      "Batch: 100/1235. Train Loss: 0.022  Acc: 87 \n",
      "Batch: 150/1235. Train Loss: 0.021  Acc: 87 \n",
      "Batch: 200/1235. Train Loss: 0.021  Acc: 88 \n",
      "Batch: 250/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 300/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 350/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 400/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 450/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 500/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 550/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 600/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 650/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 700/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 750/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 800/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 850/1235. Train Loss: 0.019  Acc: 88 \n",
      "Batch: 900/1235. Train Loss: 0.019  Acc: 88 \n",
      "Batch: 950/1235. Train Loss: 0.019  Acc: 88 \n",
      "Batch: 1000/1235. Train Loss: 0.019  Acc: 88 \n",
      "Batch: 1050/1235. Train Loss: 0.019  Acc: 88 \n",
      "Batch: 1100/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 1150/1235. Train Loss: 0.020  Acc: 88 \n",
      "Batch: 1200/1235. Train Loss: 0.019  Acc: 88 \n",
      "Time/epoch: 619\n",
      "-----------\n",
      "Epoch:  2 Val. Loss: 0.028.  Acc: 88. F1:  0.087\n",
      "Correct ratio: 0.6\n",
      "Save. Epoch:  3\n",
      "Epoch 4/10\n",
      "----------\n",
      "Batch:  50/1235. Train Loss: 0.018  Acc: 89 \n",
      "Batch: 100/1235. Train Loss: 0.019  Acc: 88 \n",
      "Batch: 150/1235. Train Loss: 0.018  Acc: 89 \n",
      "Batch: 200/1235. Train Loss: 0.017  Acc: 89 \n",
      "Batch: 250/1235. Train Loss: 0.016  Acc: 90 \n",
      "Batch: 300/1235. Train Loss: 0.016  Acc: 90 \n",
      "Batch: 350/1235. Train Loss: 0.016  Acc: 90 \n",
      "Batch: 400/1235. Train Loss: 0.016  Acc: 90 \n",
      "Batch: 450/1235. Train Loss: 0.016  Acc: 90 \n",
      "Batch: 500/1235. Train Loss: 0.016  Acc: 90 \n",
      "Batch: 550/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 600/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 650/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 700/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 750/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 800/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 850/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 900/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 950/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 1000/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 1050/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 1100/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 1150/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 1200/1235. Train Loss: 0.015  Acc: 90 \n",
      "Time/epoch: 619\n",
      "-----------\n",
      "Epoch:  3 Val. Loss: 0.033.  Acc: 88. F1:  0.295\n",
      "Correct ratio: 0.64\n",
      "Save. Epoch:  4\n",
      "Epoch 5/10\n",
      "----------\n",
      "Batch:  50/1235. Train Loss: 0.014  Acc: 91 \n",
      "Batch: 100/1235. Train Loss: 0.015  Acc: 90 \n",
      "Batch: 150/1235. Train Loss: 0.014  Acc: 91 \n",
      "Batch: 200/1235. Train Loss: 0.013  Acc: 92 \n",
      "Batch: 250/1235. Train Loss: 0.013  Acc: 92 \n",
      "Batch: 300/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 350/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 400/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 450/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 500/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 550/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 600/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 650/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 700/1235. Train Loss: 0.012  Acc: 92 \n",
      "Batch: 750/1235. Train Loss: 0.012  Acc: 93 \n",
      "Batch: 800/1235. Train Loss: 0.011  Acc: 93 \n",
      "Batch: 850/1235. Train Loss: 0.011  Acc: 93 \n",
      "Batch: 900/1235. Train Loss: 0.011  Acc: 93 \n"
     ]
    }
   ],
   "source": [
    "heuristik.train_model(epochs = args.epochs, \n",
    "                      model = model, \n",
    "                      dl_train = dl_train,\n",
    "                      dl_val = dl_val, \n",
    "                      file_name = 'BaseModel_rezero',\n",
    "                      device = device,\n",
    "                      print_freq=args.print_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
